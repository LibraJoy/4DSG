In our project, a total of 7 models are used. The versions and download links/methods for each model are as follows:
1. anygrasp: when you get anygrasp license from [here](https://github.com/graspnet/anygrasp_sdk/blob/main/README.md#license-registration), it will provid checkpoint for you.
2. bert-base-uncased: [https://huggingface.co/google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased)
3. CLIP-ViT-H-14-laion2B-s32B-b79K: [https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K](https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K)
4. droid-slam: [https://drive.google.com/file/u/0/d/1PpqVt1H4maBa_GbPJp4NwxRsd9jk-elh/view?usp=sharing&pli=1](https://drive.google.com/file/u/0/d/1PpqVt1H4maBa_GbPJp4NwxRsd9jk-elh/view?usp=sharing&pli=1)
5. GroundingDINO: [https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth](https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth) and [https://github.com/IDEA-Research/GroundingDINO/blob/main/groundingdino/config/GroundingDINO_SwinT_OGC.py](https://github.com/IDEA-Research/GroundingDINO/blob/main/groundingdino/config/GroundingDINO_SwinT_OGC.py)
6. recognize_anything: [https://huggingface.co/spaces/xinyu1205/Recognize_Anything-Tag2Text/blob/main/ram_swin_large_14m.pth](https://huggingface.co/spaces/xinyu1205/Recognize_Anything-Tag2Text/blob/main/ram_swin_large_14m.pth)
7. segment-anything-2: [https://github.com/facebookresearch/sam2?tab=readme-ov-file#download-checkpoints](https://github.com/facebookresearch/sam2?tab=readme-ov-file#download-checkpoints)

<!-- Alternatively, you can download all the checkpoints we use in the project from <a herf="">here</a>. Note that for the anygrasp model, you will need to obtain a custom license and checkpoint based on your device ID. -->

You should organize the checkpoints as follows:
```bash
DovSG/
    â”œâ”€â”€ checkpoints
    â”‚   â”œâ”€â”€ anygrasp
    â”‚   â”‚   â”œâ”€â”€ checkpoint_detection.tar
    â”‚   â”‚   â””â”€â”€ checkpoint_tracking.tar
    â”‚   â”œâ”€â”€ bert-base-uncased
    â”‚   â”‚   â”œâ”€â”€ config.json
    â”‚   â”‚   â”œâ”€â”€ model.safetensors
    â”‚   â”‚   â”œâ”€â”€ tokenizer_config.json
    â”‚   â”‚   â”œâ”€â”€ tokenizer.json
    â”‚   â”‚   â””â”€â”€ vocab.txt
    â”‚   â”œâ”€â”€ CLIP-ViT-H-14-laion2B-s32B-b79K
    â”‚   â”‚   â””â”€â”€ open_clip_pytorch_model.bin
    â”‚   â”œâ”€â”€ droid-slam
    â”‚   â”‚   â””â”€â”€ droid.pth
    â”‚   â”œâ”€â”€ GroundingDINO
    â”‚   â”‚   â”œâ”€â”€ groundingdino_swint_ogc.pth
    â”‚   â”‚   â””â”€â”€ GroundingDINO_SwinT_OGC.py
    â”‚   â”œâ”€â”€ recognize_anything
    â”‚   â”‚   â””â”€â”€ ram_swin_large_14m.pth
    â”‚   â””â”€â”€ segment-anything-2
    â”‚       â””â”€â”€ sam2_hiera_large.pt
    â””â”€â”€ license
        â”œâ”€â”€ licenseCfg.json
        â”œâ”€â”€ ZhijieYan.lic
        â”œâ”€â”€ ZhijieYan.public_key
        â””â”€â”€ ZhijieYan.signature
    ...  
```

ðŸŽ‰ now, everything is ok, let's try it.
